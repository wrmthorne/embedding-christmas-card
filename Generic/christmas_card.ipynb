{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Christmas Card Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f22b81cd8d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from songs.txt format\n",
    "Read in lyrics from lyrics file. Lyrics are supplied in the format: Title\\n\\nArtist\\n\\nLyrics\\n\\n\\nTitle2... Then save to tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('lyrics.txt') as file:\n",
    "    songs = file.read().split('\\n\\n\\n')\n",
    "\n",
    "songs_df = pd.DataFrame(dict(Title=[], Artist=[], Lyrics=[]))\n",
    "\n",
    "for song in songs:\n",
    "    title, artist, lyrics = song.split('\\n\\n')\n",
    "    songs_df = songs_df.append(dict(Title=title, Artist=artist, Lyrics=lyrics), ignore_index=True)\n",
    "\n",
    "songs_df.to_csv('songs.tsv', sep='\\t')\n",
    "\n",
    "#print(songs_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from songs.tsv format\n",
    "Read in lyrics from lyrics file. Lyrics are in a tsv matching the structure of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df = pd.read_csv('songs.tsv', sep='\\t')\n",
    "\n",
    "#print(songs_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean lyrics by removing puntuation and converting all characters into lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words: 22659\n",
      "Unique Words: 2707\n"
     ]
    }
   ],
   "source": [
    "def pre_process(lyrics):\n",
    "    # Remove newlines and split into words\n",
    "    split_lyrics = lyrics.replace('\\n', ' ').split()\n",
    "\n",
    "    # Remove all punctuation and convert all words to lower case\n",
    "    lyrics = [re.sub(r'[^\\w\\s]', '', word.lower()) for word in split_lyrics]\n",
    "    lyrics = list(filter(lambda x: x != '', lyrics)) # Remove empty string from puctuation removal\n",
    "    return ' '.join(lyrics)\n",
    "\n",
    "\n",
    "songs_df.Lyrics = songs_df.Lyrics.apply(lambda x: pre_process(x))\n",
    "\n",
    "vocabulary = set()\n",
    "songs_df.Lyrics.apply(lambda x: vocabulary.update(x.split()))\n",
    "\n",
    "total_size = sum(songs_df.Lyrics.apply(lambda x: len(x.split())))\n",
    "vocab_size = len(vocabulary)\n",
    "\n",
    "print(f'Total Words: {total_size}')\n",
    "print(f'Unique Words: {vocab_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create context target tuples to be used in the embedding training. Number of tuples generated should be the sum of the number of words $m$ in each song - the total number of songs $n$ * 2 * CONTEXT_SIZE. This number of terms is lost because a context window is required before and after the target middle term and as such, the 'boundary' tokens cannot be used as targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 22371\n",
      "Actual: 22371\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE  = 2   # Number of terms to look back/ahead for each word\n",
    "EMBEDDING_DIM = 256 # Size of each embedding vector\n",
    "\n",
    "word_to_ix = {word: i for i, word in enumerate(vocabulary)}\n",
    "\n",
    "context_targets = []\n",
    "\n",
    "def get_context_targets(lyrics):\n",
    "    split_lyrics = lyrics.split()\n",
    "\n",
    "    for i in range(CONTEXT_SIZE, len(split_lyrics) - CONTEXT_SIZE):\n",
    "        # Context is CONTEXT_SIZE words before and after word i, not including word i\n",
    "        context = split_lyrics[i-CONTEXT_SIZE:i] + split_lyrics[i+1:i+CONTEXT_SIZE+1]\n",
    "        context_targets.append((context, split_lyrics[i]))\n",
    "\n",
    "\n",
    "songs_df.Lyrics.apply(lambda x: get_context_targets(x))\n",
    "\n",
    "print(f'Expected: {total_size - len(songs_df) * 2 * CONTEXT_SIZE}')\n",
    "print(f'Actual: {len(context_targets)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to retrieve the id values for a context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the words for a context into their ix form as a tensor\n",
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = [word_to_ix[w] for w in context]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(2 * context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # reshape tensor to be 1D tensor instead of 2D, metrix like tensor\n",
    "        embeds = self.embeddings(input).view((1, -1))\n",
    "        out = self.linear1(embeds)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.softmax(out, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22371/22371 [00:18<00:00, 1218.99it/s]\n",
      "100%|██████████| 22371/22371 [00:18<00:00, 1226.02it/s]\n",
      "100%|██████████| 22371/22371 [00:19<00:00, 1165.92it/s]\n",
      "100%|██████████| 22371/22371 [00:20<00:00, 1117.97it/s]\n",
      "100%|██████████| 22371/22371 [00:19<00:00, 1129.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.168875810748432, -8.176999069895828, -8.18515699992713, -8.193350593617652, -8.201579383487115]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 5\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "model = CBOW(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimiser = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for context, target in tqdm(context_targets):\n",
    "        context_idx = make_context_vector(context, word_to_ix)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        log_probs = model(context_idx)\n",
    "\n",
    "        loss = criterion(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    losses.append(total_loss)\n",
    "\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the current version of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('word_to_ix.txt', 'w') as file:\n",
    "    json_string = json.dumps(word_to_ix)\n",
    "    file.write(json_string)\n",
    "\n",
    "torch.save(model, 'christmas_embeddings.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an existing version of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(2 * context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # reshape tensor to be 1D tensor instead of 2D, metrix like tensor\n",
    "        embeds = self.embeddings(input).view((1, -1))\n",
    "        out = self.linear1(embeds)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "# Load the model and the word_to_ix dictionary\n",
    "model = torch.load('christmas_embeddings.pt')\n",
    "with open('word_to_ix.txt', 'r') as json_file:\n",
    "    word_to_ix = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the graph\n",
    "Set the two words to draw the vectors to. Ensure the words are lower case and match any pre-processing applied. Also set the number of points other than the to specified points to render. 400 looks good but can be changed if a denser or sparser snowstorm is desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_1 = 'te'\n",
    "WORD_2 = 'amo'\n",
    "\n",
    "NUM_POINTS = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the snowflake SVG and create a custome matplotlib marker with it. Then reduce the dimensionality of the embeddings down to 3 dimensions to be represented in 3D scatter plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4793/216566724.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mall_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword1_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;31m#y_data = pca_results[all_idxs, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#z_data = pca_results[all_idxs, 2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from svgpathtools import svg2paths\n",
    "from svgpath2mpl import parse_path\n",
    "\n",
    "snowflake_path, attributes = svg2paths('snowflake.svg')\n",
    "snowflake_marker = parse_path(attributes[0]['d'])\n",
    "snowflake_marker.vertices -= snowflake_marker.vertices.mean(axis=0)\n",
    "snowflake_marker = snowflake_marker.transformed(mpl.transforms.Affine2D().rotate_deg(180))\n",
    "snowflake_marker = snowflake_marker.transformed(mpl.transforms.Affine2D().scale(-1,1))\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_results = pca.fit_transform(model.embeddings.weight.detach())\n",
    "\n",
    "fig = plt.figure( figsize=(20, 20))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.axis('off')\n",
    "ax.set_facecolor('black')\n",
    "\n",
    "word1_idx = word_to_ix[WORD_1]\n",
    "word2_idx = word_to_ix[WORD_2]\n",
    "\n",
    "num = len(word_to_ix)\n",
    "np.random.seed(0)\n",
    "random_idxs = np.random.randint(low=0, high=num, size=NUM_POINTS)\n",
    "\n",
    "all_idxs = np.append(random_idxs, [word1_idx, word2_idx])\n",
    "x_data = pca_results[all_idxs, 0]\n",
    "y_data = pca_results[all_idxs, 1]\n",
    "z_data = pca_results[all_idxs, 2]\n",
    "\n",
    "ax.set_title('Christmas Embeddings', fontsize=20)\n",
    "ax.invert_zaxis() # Z-Axis inverted in this example to make the words appear in the right order\n",
    "ax.scatter3D(x_data, y_data, z_data, s=70, c='white', marker=snowflake_marker)\n",
    "\n",
    "x_1 = [0, pca_results[word1_idx, 0]]\n",
    "y_1 = [0, pca_results[word1_idx, 1]]\n",
    "z_1 = [0, pca_results[word1_idx, 2]]\n",
    "\n",
    "x_2 = [0, pca_results[word2_idx, 0]]\n",
    "y_2 = [0, pca_results[word2_idx, 1]]\n",
    "z_2 = [0, pca_results[word2_idx, 2]]\n",
    "\n",
    "ax.plot(x_1, y_1, z_1, color='#bb2528')\n",
    "ax.plot(x_2, y_2, z_2, color='#146b3a')\n",
    "\n",
    "t_1 = ax.text(pca_results[word1_idx, 0], pca_results[word1_idx, 1], pca_results[word1_idx, 2], WORD_1, fontsize=30, c='#bb2528')\n",
    "t_1.set_bbox(dict(facecolor='black', alpha=0.75, edgecolor='black'))\n",
    "\n",
    "t_2 = ax.text(pca_results[word2_idx, 0], pca_results[word2_idx, 1], pca_results[word2_idx, 2], WORD_2, fontsize=30, c='#146b3a')\n",
    "t_2.set_bbox(dict(facecolor='black', alpha=0.75, edgecolor='black'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
